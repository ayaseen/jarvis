<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>vLLM Model Manager - JARVIS</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            color: #fff;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
        }

        .header {
            text-align: center;
            margin-bottom: 40px;
        }

        .header h1 {
            font-size: 3em;
            margin-bottom: 10px;
            text-shadow: 0 0 20px rgba(0, 212, 255, 0.5);
        }

        .header p {
            color: #00d4ff;
            font-size: 1.2em;
        }

        .back-btn {
            display: inline-block;
            padding: 10px 20px;
            background: rgba(0, 212, 255, 0.2);
            border: 2px solid #00d4ff;
            border-radius: 25px;
            color: #00d4ff;
            text-decoration: none;
            margin-bottom: 20px;
            transition: all 0.3s;
        }

        .back-btn:hover {
            background: rgba(0, 212, 255, 0.3);
            transform: scale(1.05);
        }

        .status-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-bottom: 40px;
        }

        .status-item {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 20px;
            text-align: center;
        }

        .status-label {
            color: #888;
            font-size: 0.9em;
            margin-bottom: 10px;
            text-transform: uppercase;
        }

        .status-value {
            font-size: 1.5em;
            font-weight: bold;
        }

        .status-good {
            color: #4ade80;
        }

        .status-bad {
            color: #ff4444;
        }

        .status-warning {
            color: #ffa500;
        }

        .main-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
        }

        .card {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 30px;
        }

        .card h2 {
            color: #00d4ff;
            margin-bottom: 20px;
            font-size: 1.5em;
        }

        .current-config {
            background: rgba(0, 0, 0, 0.3);
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
        }

        .config-item {
            display: flex;
            justify-content: space-between;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }

        .config-label {
            color: #888;
        }

        .config-value {
            color: #00d4ff;
            font-weight: bold;
        }

        .alert {
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
        }

        .alert-info {
            background: rgba(0, 123, 255, 0.2);
            border: 1px solid #007bff;
        }

        .alert-success {
            background: rgba(40, 167, 69, 0.2);
            border: 1px solid #28a745;
        }

        .form-group {
            margin-bottom: 20px;
        }

        .form-group label {
            display: block;
            margin-bottom: 8px;
            color: #00d4ff;
        }

        .form-group input,
        .form-group select {
            width: 100%;
            padding: 10px;
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(0, 212, 255, 0.3);
            border-radius: 5px;
            color: #fff;
            font-size: 1em;
        }

        .slider-container {
            display: flex;
            align-items: center;
            gap: 15px;
        }

        .slider {
            flex: 1;
            -webkit-appearance: none;
            height: 5px;
            border-radius: 5px;
            background: rgba(255, 255, 255, 0.2);
            outline: none;
        }

        .slider::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 20px;
            height: 20px;
            border-radius: 50%;
            background: #00d4ff;
            cursor: pointer;
        }

        .slider-value {
            color: #00d4ff;
            font-weight: bold;
            min-width: 50px;
        }

        button {
            padding: 12px 30px;
            background: rgba(0, 212, 255, 0.2);
            border: 2px solid #00d4ff;
            border-radius: 25px;
            color: #fff;
            font-size: 1em;
            cursor: pointer;
            transition: all 0.3s;
        }

        button:hover {
            background: rgba(0, 212, 255, 0.3);
            transform: scale(1.05);
        }

        .model-list {
            max-height: 400px;
            overflow-y: auto;
        }

        .model-item {
            background: rgba(0, 0, 0, 0.3);
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 15px;
            cursor: pointer;
            transition: all 0.3s;
            border: 2px solid transparent;
        }

        .model-item:hover {
            background: rgba(0, 0, 0, 0.5);
            border-color: rgba(0, 212, 255, 0.3);
        }

        .model-item.selected {
            border-color: #00d4ff;
            background: rgba(0, 212, 255, 0.1);
        }

        .model-name {
            color: #00d4ff;
            font-weight: bold;
            margin-bottom: 5px;
        }

        .model-desc {
            color: #ccc;
            font-size: 0.9em;
            margin-bottom: 10px;
        }

        .model-specs {
            display: flex;
            gap: 10px;
        }

        .spec-badge {
            background: rgba(0, 212, 255, 0.2);
            padding: 3px 8px;
            border-radius: 5px;
            font-size: 0.8em;
        }

        .category-header {
            color: #ffa500;
            font-weight: bold;
            margin: 20px 0 10px 0;
            font-size: 1.1em;
        }

        .command-box {
            background: #1a1a2e;
            padding: 15px;
            border-radius: 5px;
            font-family: 'Courier New', monospace;
            margin: 10px 0;
            position: relative;
        }

        .copy-btn {
            position: absolute;
            right: 10px;
            top: 50%;
            transform: translateY(-50%);
            padding: 5px 15px;
            font-size: 0.9em;
        }

        #updateResult {
            margin-top: 20px;
        }

        @media (max-width: 768px) {
            .main-grid {
                grid-template-columns: 1fr;
            }

            .status-grid {
                grid-template-columns: 1fr 1fr;
            }
        }
    </style>
</head>

<body>
    <div class="container">
        <a href="/" class="back-btn">← Back to JARVIS Chat</a>

        <div class="header">
            <h1>⚡ vLLM Model Manager</h1>
            <p>High-Performance Model Serving for RTX 4070 Ti</p>
        </div>

        <!-- Status Overview -->
        <div class="status-grid">
            <div class="status-item">
                <div class="status-label">vLLM Status</div>
                <div class="status-value" id="vllmStatus">
                    <span class="status-warning">Checking...</span>
                </div>
            </div>
            <div class="status-item">
                <div class="status-label">Current Model</div>
                <div class="status-value" id="currentModel">
                    <span class="status-warning">Loading...</span>
                </div>
            </div>
            <div class="status-item">
                <div class="status-label">GPU Memory</div>
                <div class="status-value" id="gpuMemory">
                    <span class="status-warning">--</span>
                </div>
            </div>
            <div class="status-item">
                <div class="status-label">Max Context</div>
                <div class="status-value" id="maxContext">
                    <span class="status-warning">--</span>
                </div>
            </div>
        </div>

        <div class="main-grid">
            <!-- Current Configuration -->
            <div class="card">
                <h2>⚙️ Current Configuration</h2>

                <div class="current-config">
                    <div class="config-item">
                        <span class="config-label">Model Path:</span>
                        <span class="config-value" id="configModel">--</span>
                    </div>
                    <div class="config-item">
                        <span class="config-label">Quantization:</span>
                        <span class="config-value" id="configQuant">AWQ</span>
                    </div>
                    <div class="config-item">
                        <span class="config-label">Max Tokens:</span>
                        <span class="config-value" id="configMaxLen">2048</span>
                    </div>
                    <div class="config-item">
                        <span class="config-label">GPU Utilization:</span>
                        <span class="config-value" id="configGpuUtil">50%</span>
                    </div>
                </div>

                <div class="alert alert-info">
                    <strong>Note:</strong> vLLM loads one model at startup. To change models, update the configuration
                    below and restart the container.
                </div>

                <h3 style="margin-top: 20px; margin-bottom: 15px; color: #00d4ff;">Update Configuration</h3>

                <div class="form-group">
                    <label for="modelInput">Model (HuggingFace path or local):</label>
                    <input type="text" id="modelInput" placeholder="e.g., TheBloke/Mistral-7B-Instruct-v0.2-AWQ">
                </div>

                <div class="form-group">
                    <label for="maxTokens">Max Context Length:</label>
                    <select id="maxTokens">
                        <option value="2048">2048 tokens</option>
                        <option value="4096">4096 tokens</option>
                        <option value="8192">8192 tokens</option>
                        <option value="16384">16384 tokens</option>
                        <option value="32768">32768 tokens (Mistral/Zephyr only)</option>
                    </select>
                </div>

                <div class="form-group">
                    <label for="gpuMemorySlider">GPU Memory Utilization:</label>
                    <div class="slider-container">
                        <input type="range" class="slider" id="gpuMemorySlider" min="50" max="95" value="50">
                        <span class="slider-value" id="gpuMemoryValue">50%</span>
                    </div>
                </div>

                <button onclick="updateConfiguration()" id="updateBtn">Update Configuration</button>

                <div id="updateResult"></div>
            </div>

            <!-- Available Models -->
            <div class="card">
                <h2>🚀 Recommended Models for RTX 4070 Ti</h2>

                <div class="model-list" id="modelList">
                    <div class="category-header">⭐ Best Performance (AWQ Quantized)</div>

                    <div class="model-item" onclick="selectModel('TheBloke/Mistral-7B-Instruct-v0.2-AWQ')">
                        <div class="model-name">Mistral-7B-Instruct-v0.2-AWQ</div>
                        <div class="model-desc">Excellent general-purpose model with 32K context</div>
                        <div class="model-specs">
                            <span class="spec-badge">4.2GB</span>
                            <span class="spec-badge">AWQ</span>
                            <span class="spec-badge">32K context</span>
                        </div>
                    </div>

                    <div class="model-item" onclick="selectModel('TheBloke/Llama-2-7B-Chat-AWQ')">
                        <div class="model-name">Llama-2-7B-Chat-AWQ</div>
                        <div class="model-desc">Meta's conversational AI, great for dialogue</div>
                        <div class="model-specs">
                            <span class="spec-badge">3.9GB</span>
                            <span class="spec-badge">AWQ</span>
                            <span class="spec-badge">4K context</span>
                        </div>
                    </div>

                    <div class="model-item" onclick="selectModel('TheBloke/neural-chat-7B-v3-3-AWQ')">
                        <div class="model-name">neural-chat-7B-v3-3-AWQ</div>
                        <div class="model-desc">Intel's optimized conversational model</div>
                        <div class="model-specs">
                            <span class="spec-badge">4.1GB</span>
                            <span class="spec-badge">AWQ</span>
                            <span class="spec-badge">8K context</span>
                        </div>
                    </div>

                    <div class="model-item" onclick="selectModel('TheBloke/zephyr-7B-beta-AWQ')">
                        <div class="model-name">zephyr-7B-beta-AWQ</div>
                        <div class="model-desc">HuggingFace's aligned assistant, excellent responses</div>
                        <div class="model-specs">
                            <span class="spec-badge">4.2GB</span>
                            <span class="spec-badge">AWQ</span>
                            <span class="spec-badge">32K context</span>
                        </div>
                    </div>

                    <div class="category-header">🎯 Alternative Options</div>

                    <div class="model-item" onclick="selectModel('TheBloke/CodeLlama-7B-Instruct-AWQ')">
                        <div class="model-name">CodeLlama-7B-Instruct-AWQ</div>
                        <div class="model-desc">Specialized for code generation and analysis</div>
                        <div class="model-specs">
                            <span class="spec-badge">4.0GB</span>
                            <span class="spec-badge">AWQ</span>
                            <span class="spec-badge">16K context</span>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Instructions -->
        <div class="card" style="margin-top: 30px;">
            <h2>📘 How to Switch Models</h2>

            <div class="alert alert-info">
                vLLM is optimized for production serving. It loads one model at startup for maximum performance.
            </div>

            <h3 style="margin-top: 20px; color: #00d4ff;">To change the model:</h3>
            <ol style="line-height: 1.8; margin: 20px 0;">
                <li>Select a model from the list or enter a custom HuggingFace model path</li>
                <li>Adjust the context length and GPU memory settings if needed</li>
                <li>Click "Update Configuration"</li>
                <li>Restart the vLLM container:</li>
            </ol>

            <div class="command-box">
                docker-compose restart vllm
                <button class="copy-btn" onclick="copyCommand(this)">Copy</button>
            </div>

            <h3 style="margin-top: 20px; color: #00d4ff;">Monitor logs:</h3>
            <div class="command-box">
                docker-compose logs -f vllm
                <button class="copy-btn" onclick="copyCommand(this)">Copy</button>
            </div>
        </div>
    </div>

    <script>
        let selectedModel = '';
        let lastVllmStatus = null;

        // Check system status - PROPERLY CHECK vLLM
        async function checkSystemStatus() {
            console.log('Checking system status...');

            try {
                // First, try to get health status from orchestrator
                const healthResponse = await fetch('/api/health');
                let vllmHealthy = false;

                if (healthResponse.ok) {
                    const healthData = await healthResponse.json();
                    console.log('Health data:', healthData);

                    // Check vLLM status from health endpoint
                    vllmHealthy = healthData.services?.vllm === true;

                    // Update all service statuses if you have them displayed
                    console.log('vLLM healthy from orchestrator:', vllmHealthy);
                }

                // Also try direct vLLM check as backup
                if (!vllmHealthy) {
                    try {
                        // Try to get models to verify vLLM is actually responding
                        const modelsResponse = await fetch('/api/models');
                        if (modelsResponse.ok) {
                            const modelsData = await modelsResponse.json();
                            // If we can get models, vLLM must be running
                            if (modelsData.data || modelsData.models) {
                                vllmHealthy = true;
                                console.log('vLLM responding to models endpoint');
                            }
                        }
                    } catch (e) {
                        console.log('Models endpoint failed:', e);
                        vllmHealthy = false;
                    }
                }

                // Update vLLM status display - FORCE UPDATE
                const statusElement = document.getElementById('vllmStatus');
                if (statusElement) {
                    if (vllmHealthy) {
                        statusElement.innerHTML = '<span class="status-good">✓ Running</span>';
                        statusElement.className = 'status-value';
                    } else {
                        statusElement.innerHTML = '<span class="status-bad">✗ Offline</span>';
                        statusElement.className = 'status-value error';
                    }
                }

                // Log status change
                if (lastVllmStatus !== vllmHealthy) {
                    console.log('vLLM status changed from', lastVllmStatus, 'to', vllmHealthy);
                    lastVllmStatus = vllmHealthy;
                }

                // Get models info regardless of health status
                try {
                    const modelsResponse = await fetch('/api/models');
                    if (modelsResponse.ok) {
                        const modelsData = await modelsResponse.json();
                        const models = modelsData.data || modelsData.models || [];

                        if (models.length > 0) {
                            const currentModel = models[0].id;

                            // Update current model display
                            document.getElementById('currentModel').innerHTML =
                                `<span class="status-good" style="font-size: 0.9em;">${currentModel.split('/').pop()}</span>`;

                            // Update configuration display
                            document.getElementById('configModel').textContent = currentModel;
                            if (!document.getElementById('modelInput').value) {
                                document.getElementById('modelInput').value = currentModel;
                            }
                        } else {
                            // No models loaded
                            document.getElementById('currentModel').innerHTML =
                                '<span class="status-warning">No model loaded</span>';
                            document.getElementById('configModel').textContent = 'No model loaded';

                            // If no models but health check passed, vLLM might be starting
                            if (vllmHealthy) {
                                document.getElementById('vllmStatus').innerHTML =
                                    '<span class="status-warning">⟳ Starting...</span>';
                            }
                        }
                    } else {
                        // Can't reach models endpoint
                        document.getElementById('currentModel').innerHTML =
                            '<span class="status-bad">Cannot connect</span>';

                        // Override vLLM status to offline if we can't get models
                        document.getElementById('vllmStatus').innerHTML =
                            '<span class="status-bad">✗ Offline</span>';
                    }
                } catch (error) {
                    console.error('Models fetch error:', error);
                    document.getElementById('currentModel').innerHTML =
                        '<span class="status-bad">Connection error</span>';

                    // If we can't reach models, vLLM is definitely down
                    document.getElementById('vllmStatus').innerHTML =
                        '<span class="status-bad">✗ Offline</span>';
                }

                // Update GPU and context info (from env or defaults)
                const gpuMemory = 50; // Your .env default
                const maxContext = 2048; // Your .env default

                document.getElementById('gpuMemory').innerHTML =
                    vllmHealthy ? `<span class="status-good">${gpuMemory}%</span>` : '<span class="status-warning">--</span>';

                document.getElementById('maxContext').innerHTML =
                    vllmHealthy ? `<span class="status-good">${maxContext}</span>` : '<span class="status-warning">--</span>';

                // Update config display
                document.getElementById('configMaxLen').textContent = maxContext;
                document.getElementById('configGpuUtil').textContent = gpuMemory + '%';

                // Update form controls
                if (!document.getElementById('maxTokens').value) {
                    document.getElementById('maxTokens').value = maxContext;
                }
                if (!document.getElementById('gpuMemorySlider').value) {
                    document.getElementById('gpuMemorySlider').value = gpuMemory;
                    document.getElementById('gpuMemoryValue').textContent = gpuMemory + '%';
                }

            } catch (error) {
                console.error('Status check failed:', error);

                // On complete failure, mark everything as offline
                document.getElementById('vllmStatus').innerHTML =
                    '<span class="status-bad">✗ Connection Error</span>';
                document.getElementById('currentModel').innerHTML =
                    '<span class="status-warning">Unable to connect</span>';
                document.getElementById('gpuMemory').innerHTML =
                    '<span class="status-warning">--</span>';
                document.getElementById('maxContext').innerHTML =
                    '<span class="status-warning">--</span>';
            }
        }

        // Test function to verify status updates
        function testStatusUpdate() {
            console.log('Testing status update...');
            // Manually set to offline
            document.getElementById('vllmStatus').innerHTML = '<span class="status-bad">✗ TEST OFFLINE</span>';
            setTimeout(() => {
                checkSystemStatus();
            }, 2000);
        }

        // Select a model from the list
        function selectModel(modelName) {
            selectedModel = modelName;
            document.getElementById('modelInput').value = modelName;

            // Update visual selection
            document.querySelectorAll('.model-item').forEach(item => {
                item.classList.remove('selected');
            });
            if (event && event.currentTarget) {
                event.currentTarget.classList.add('selected');
            }

            // Auto-select appropriate context length
            if (modelName.includes('Mistral') || modelName.includes('zephyr')) {
                document.getElementById('maxTokens').value = '32768';
            } else if (modelName.includes('CodeLlama')) {
                document.getElementById('maxTokens').value = '16384';
            } else if (modelName.includes('neural-chat')) {
                document.getElementById('maxTokens').value = '8192';
            } else {
                document.getElementById('maxTokens').value = '4096';
            }
        }

        // Update configuration
        async function updateConfiguration() {
            const model = document.getElementById('modelInput').value;
            const maxTokens = document.getElementById('maxTokens').value;
            const gpuMemory = document.getElementById('gpuMemorySlider').value;

            if (!model) {
                alert('Please select or enter a model!');
                return;
            }

            document.getElementById('updateBtn').disabled = true;
            document.getElementById('updateBtn').textContent = 'Updating...';

            try {
                // Call backend to update configuration
                const response = await fetch('/api/models/update', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        model: model,
                        max_tokens: parseInt(maxTokens),
                        gpu_memory: parseFloat(gpuMemory) / 100
                    })
                });

                if (response.ok) {
                    const result = await response.json();
                    document.getElementById('updateResult').innerHTML = `
                    <div class="alert alert-success">
                        <h4>✅ Model Update Initiated!</h4>
                        <p>vLLM is restarting with the new model: <strong>${model}</strong></p>
                        <p>This may take 30-60 seconds...</p>
                        <div id="restart-progress" style="margin-top: 10px;">
                            <span style="color: #ffa500;">⏳ Waiting for vLLM to restart...</span>
                        </div>
                    </div>
                `;

                    // Monitor restart
                    monitorRestart(model);
                } else {
                    throw new Error('Update endpoint returned error');
                }
            } catch (error) {
                console.error('Update failed:', error);

                // Show manual instructions
                const envConfig = `# Update your .env file:
VLLM_MODEL=${model}
VLLM_MAX_MODEL_LEN=${maxTokens}
VLLM_GPU_MEMORY=${(gpuMemory / 100).toFixed(2)}

# Then restart:
docker-compose restart vllm`;

                document.getElementById('updateResult').innerHTML = `
                <div class="alert alert-warning">
                    <h4>⚠️ Manual update required</h4>
                    <pre style="background: #1a1a2e; padding: 15px; border-radius: 5px;">${envConfig}</pre>
                </div>
            `;
            } finally {
                document.getElementById('updateBtn').disabled = false;
                document.getElementById('updateBtn').textContent = 'Update Configuration';
            }
        }

        // Monitor vLLM restart
        async function monitorRestart(expectedModel) {
            let attempts = 0;
            const maxAttempts = 30;
            let wasOffline = false;

            const checkInterval = setInterval(async () => {
                attempts++;
                const progressElement = document.getElementById('restart-progress');

                try {
                    // Check health
                    const healthResponse = await fetch('/api/health');
                    let vllmHealthy = false;

                    if (healthResponse.ok) {
                        const healthData = await healthResponse.json();
                        vllmHealthy = healthData.services?.vllm === true;
                    }

                    if (!vllmHealthy) {
                        wasOffline = true;
                        if (progressElement) {
                            progressElement.innerHTML = `<span style="color: #ff4444;">⏳ vLLM is offline, waiting for restart... (${attempts * 2}s)</span>`;
                        }
                        // Update main status too
                        document.getElementById('vllmStatus').innerHTML = '<span class="status-warning">⟳ Restarting...</span>';
                    } else if (wasOffline) {
                        // vLLM is back online, check if model is loaded
                        const modelsResponse = await fetch('/api/models');
                        if (modelsResponse.ok) {
                            const data = await modelsResponse.json();
                            const models = data.data || data.models || [];

                            if (models.length > 0 && models[0].id === expectedModel) {
                                // Success!
                                if (progressElement) {
                                    progressElement.innerHTML = '<span style="color: #4ade80;">✅ Model loaded successfully!</span>';
                                }

                                // Refresh main status
                                checkSystemStatus();

                                // Clear result after 3 seconds
                                setTimeout(() => {
                                    document.getElementById('updateResult').innerHTML = '';
                                }, 3000);

                                clearInterval(checkInterval);
                            } else {
                                if (progressElement) {
                                    progressElement.innerHTML = `<span style="color: #ffa500;">⏳ Loading model... (${attempts * 2}s)</span>`;
                                }
                            }
                        }
                    }
                } catch (error) {
                    console.error('Monitor error:', error);
                    if (progressElement) {
                        progressElement.innerHTML = `<span style="color: #ffa500;">⏳ Checking... (${attempts * 2}s)</span>`;
                    }
                }

                if (attempts >= maxAttempts) {
                    if (progressElement) {
                        progressElement.innerHTML = '<span style="color: #ff4444;">⚠️ Timeout - Please check Docker logs</span>';
                    }
                    clearInterval(checkInterval);
                    checkSystemStatus(); // Final status check
                }
            }, 2000);
        }

        // Copy command helper
        function copyCommand(button) {
            const commandBox = button.parentElement;
            const command = commandBox.firstChild.textContent.trim();
            navigator.clipboard.writeText(command).then(() => {
                const originalText = button.textContent;
                button.textContent = 'Copied!';
                setTimeout(() => {
                    button.textContent = originalText;
                }, 2000);
            });
        }

        // GPU slider handler
        document.getElementById('gpuMemorySlider').addEventListener('input', function () {
            document.getElementById('gpuMemoryValue').textContent = this.value + '%';
        });

        // Initial load
        console.log('Initial status check...');
        checkSystemStatus();

        // Check status every 5 seconds (more frequent for better responsiveness)
        setInterval(() => {
            console.log('Periodic status check...');
            checkSystemStatus();
        }, 5000);

        // Add keyboard shortcut for manual refresh (Ctrl+R)
        document.addEventListener('keydown', (e) => {
            if (e.ctrlKey && e.key === 'r') {
                e.preventDefault();
                console.log('Manual refresh triggered');
                checkSystemStatus();
            }
        });
    </script>
</body>

</html>
